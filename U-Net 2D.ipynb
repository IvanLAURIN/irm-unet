{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92d2b9c1-78c9-4c81-8b0d-4e8de5a87367",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Entraînement d'un réseau U-Net pour la segmentation de tumeurs dans des images 2D issues du dataset BraTS 2019\n",
    "\n",
    "Le code présenté ci-dessous permet la création, l'entraînement et l'évaluation d'un modèle de réseau de neurones reprenant l'architecture U-Net pour la segmentation de tissus tumoraux."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a189eb75-736b-411d-9dbc-6e5b94377f81",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Cette section détaille les entrées-sorties de ce programme, ainsi que la configuration recommandée et les librairies utilisées pour le faire fonctionner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369ee36a-5c17-4e89-b41d-b69c8ab08671",
   "metadata": {},
   "source": [
    "### Données d'entrée\n",
    "\n",
    "Ce code fonctionne en conjonction avec le code de pré-traîtement des données de la base BraTS 2019 fourni. Il permet de travailler avec des données multimodales en empilant les données issues des acquisitions suivantes : \n",
    "-  Pondération T1 (T1)\n",
    "-  Pondération T1 avec augmentation du contraste (T1CE)\n",
    "-  Pondération T2 (T2)\n",
    "-  Pondération T2 avec atténuation des fluides par inversion-récupération (FLAIR)\n",
    "\n",
    "Se reporter à la [page de description du dataset BraTS 2019](https://www.med.upenn.edu/cbica/brats2019/data.html) pour plus d'informations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428ba2ba-59b6-43f0-a127-08cddc9b9675",
   "metadata": {},
   "source": [
    "### Données de sortie\n",
    "\n",
    "Le modèle permet de générer une segmentation en 5 classes qui sont : \n",
    "-  Extérieur du cerveau - (classe 0)\n",
    "-  Tissu sain - (classe 1)\n",
    "-  *Necrotic and non-enhancing tumor core* - (classe 2)\n",
    "-  *Peritumoral edema* - (classe 3)\n",
    "-  *GD-enhancing tumor* - (classe 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c95cef-97f9-45fe-accc-2656e09981a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Configuration\n",
    "\n",
    "Ce code a été conçu et testé avec la configuration suivante : \n",
    "-  Python 3.10\n",
    "-  CUDA Toolkit 11.2\n",
    "-  CuDNN 8.1\n",
    "-  Tensorflow 2.10\n",
    "-  Pandas 1.5\n",
    "-  Matplotlib 3.7\n",
    "-  Scikit-learn 1.2\n",
    "\n",
    "Il nécessite l'import des librairies et fonctions suivantes : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3839f7d-8b72-41ea-993f-917d18cae5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45acd981-e2bb-4d12-93dc-0b666d6d1049",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Création des datasets\n",
    "\n",
    "Cette section détaille la façon dont sont organisés et construits les datasets d'entraînement et de validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83788dcd-ea04-47b8-8a85-d57b326c43d0",
   "metadata": {},
   "source": [
    "### Organisation des datasets d'entraînement et de validation\n",
    "\n",
    "Lors de la création des datasets d'entraînement et de validation, ceux-ci sont fractionnés en subdivisions de 500 images maximum. En effet, les données pré-traîtées étant de grande dimmensionnalité (volume 3D à 5 canaux) et compressées au format .npz, il faut compter plusieurs secondes de chargement pour accéder à ces données. Le regroupement en subdivisions permet d'aggréger uniquement les données nécessaires en volumes de taille intermédiaire, limitant le temps passé à charger/décompresser des données, mais suffisament grands pour permettre un mélange des images lors du regroupement par batch. Les informations sur chaque image stockée dans chaque subdivision sont stockées dans un fichier d'index au format .csv. Un second fichier d'index recense les paramètres utilisés pour la création de ces datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e7bc7b-55dc-4451-80e4-54eaf336f34d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Paramètres de création des datasets\n",
    "\n",
    "Dans la cellule ci-dessous, il est possible de définir tous les paramètres de création des datasets : \n",
    "-  **reuse_index** : Variable booléenne indiquant si les fichiers d'index et de paramètres existants doivent être réutilisés. Si aucun fichier d'index correspondant aux paramètres d'entraînement n'est trouvé, ce fichier est créé, ce qui cause la création de nouvelles subdivisions. En cas de réutilisation, les paramètres *channels*, *image_axis*, *train_size* et *validation_ratio* sont écrasés et remplacés par ceux présents dans les fichiers d'index.\n",
    "-  **rebuild_dataset** : Variable booléenne indiquant s'il faut reconstruire les subdivisions à partir d'un fichier d'index. Si aucun fichier d'index n'existe, les subdivisions seront recréées après ledit fichier d'index.\n",
    "-  **channels** : Liste des canaux IRM à inclure lors de l'entraînement.\n",
    "-  **image_axis** : Axe de coupe de l'image. 0 : X (plan YZ), 1 : Y (plan XZ), 2 : Z (plan XY)\n",
    "-  **train_size** : Taille du dataset d'entraînement, en nombre d'images.\n",
    "-  **validation_ratio** : Taille du dataset de validation, exprimé en proportion de la taille du dataset d'entraînement. *Par exemple, avec un ratio de 0.1 et un dataset d'entraînement de 1000 images, le dataset de validation comportera 100 images*\n",
    "\n",
    "Attention, s'il est indiqué que les ensembles d'entraînement et de validation doivent inclure plus d'images que n'en contient la base, ceux-ci seront redimensionnés en conservant leur ratio pour inclure toutes les images de la base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56829e93-35a5-4e36-ad79-ea833aefd13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres de création des datasets\n",
    "\n",
    "reuse_index = True \n",
    "rebuild_dataset = False\n",
    "channels = [\"flair\",\"t1\", \"t1ce\", \"t2\"]\n",
    "image_axis = 2\n",
    "train_size = 1000\n",
    "validation_ratio = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d850300d-7d62-45c7-804e-7dca2d15e227",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Construction des fichiers d'index\n",
    "\n",
    "La fonction ci-dessous se charge de créer les fichiers d'index permettant la construction des datasets. \n",
    "\n",
    "Le premier fichier d'index (appelé par la suite le *fichier de paramètres*) contient les paramètres de création des datasets suivants : \n",
    "-  **image_axis** : Axe de coupe des images\n",
    "-  **channels** : Canaux utilisés\n",
    "-  **img_shape** : Dimensions des images sélectionnées\n",
    "-  **train_size** : Taille du dataset d'entraînement\n",
    "-  **validation_ratio** : Taille du dataset de validation\n",
    "\n",
    "Le second fichier d'index (appelé par la suite le *fichier d'annuaire*) permet de garder la trace des images sélectionnées dans chaque subdivision des datasets. Il s'agit d'in fichier .csv avec les champs suivants, détaillés pour chaque image incluse dans les datasets : \n",
    "-  **subset_name** : Nom du fichier de subdivision dans lequel l'image est intégrée\n",
    "-  **train_or_test** : String pouvant valoir *'train'* ou *'test'* indiquant si l'image fait partie du dataset d'entraînement ou de validation\n",
    "-  **subset_position** : Position de l'image au sein de la subdivision (allant de 0 à 499)\n",
    "-  **file_name** : Chemin et nom du fichier .npz issu de la base pré-traîtée dont l'image est tirée\n",
    "-  **slice** : Position de l'image dans le volume 3D dont elle est issue, suivant l'axe indiqué par *image_axis*.\n",
    "\n",
    "Ces fichiers d'index sont enregistrés dans un dossier nommé **./datasets/2d_{N}k/** qui est créé s'il n'existe pas, où **{N}** est le nombre de milliers d'images (arrondi à l'entier inférieur) incluses dans le dataset d'entraînement. Le fichier d'annuaire est nommé **index.csv**  et le fichier de paramètres est nommé **parameters.csv**. \n",
    "\n",
    "La variable d'entrée **path_to_data** est la liste des chemins vers les volumes 3D pré-traîtés d'où seront tirées les images à inclure dans les datasets, et la variable **dataset_path** est le chemin dans lequel le dataset est stocké."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000a31a0-a03d-4113-b89e-10cfef0e14e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_index(path_to_data, dataset_path, train_size, validation_ratio, image_axis, channels, img_shape):\n",
    "    \n",
    "    os.makedirs(dataset_path, exist_ok=True)\n",
    "    \n",
    "    # Construction du fichier de paramètres\n",
    "    param_file = open(os.path.join(dataset_path, 'parameters.csv'), mode='w')\n",
    "    param_names = ['image_axis', 'channels', 'img_shape', 'train_size', 'validation_ratio']\n",
    "    writer_param = csv.DictWriter(param_file, fieldnames=param_names)\n",
    "    writer_param.writeheader()\n",
    "    dico_param = {'image_axis' : image_axis, \n",
    "                  'channels' : channels, \n",
    "                  'img_shape' : img_shape, \n",
    "                  'train_size' : train_size, \n",
    "                  'validation_ratio' : validation_ratio, \n",
    "                 }\n",
    "    writer_param.writerow(dico_param)\n",
    "    param_file.close()\n",
    "    \n",
    "    # Tirage aléatoire des images qui seront incluses dans les datasets\n",
    "    rp = np.random.permutation(img_shape[3]*len(path_to_data))\n",
    "    validation_size = int(train_size* validation_ratio)\n",
    "    rp = rp[:(train_size + validation_size)]\n",
    "    datasets = []\n",
    "    for k in range(len(rp)):\n",
    "        datasets.append((path_to_data[rp[k]//img_shape[3]], rp[k]%img_shape[3]))\n",
    "\n",
    "    # Construction du fichier d'annuaire\n",
    "    index_file = open(os.path.join(dataset_path, 'index.csv'), mode='w')\n",
    "    field_names = ['subset_name', 'train_or_test', 'subset_position', 'file_name', 'slice']\n",
    "    writer = csv.DictWriter(index_file, fieldnames=field_names)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    dico = {'train_or_test' : 'train'}\n",
    "    for i in range(train_size):\n",
    "        if i % 500 == 0:\n",
    "            dico['subset_name'] = os.path.join(dataset_path, 'train_{0:d}'.format(i//500))\n",
    " \n",
    "        dico['subset_position'] = i % 500 \n",
    "        dico['file_name'] = datasets[i][0]\n",
    "        dico['slice'] = datasets[i][1]\n",
    "\n",
    "        writer.writerow(dico)\n",
    "        \n",
    "    dico['train_or_test'] = 'test'\n",
    "    for i in range(validation_size):\n",
    "        if i % 500 == 0:\n",
    "            dico['subset_name'] = os.path.join(dataset_path, 'test_{0:d}'.format(i//500))\n",
    " \n",
    "        dico['subset_position'] = i % 500\n",
    "        dico['file_name'] = datasets[i + train_size][0]\n",
    "        dico['slice'] = datasets[i + train_size][1]\n",
    "        \n",
    "        writer.writerow(dico)\n",
    "        \n",
    "    index_file.close()   \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b015316-3e28-4938-9719-39bb04114152",
   "metadata": {},
   "source": [
    "### Lecture du fichier de paramètres\n",
    "\n",
    "La fonction suivante se charge de récupérer les paramètres de création des datasets dans le fichier de paramètre. \n",
    "\n",
    "La variable d'entrée **dataset_path** contient le chemin vers le dossier dans lequel est stocké le dataset.\n",
    "\n",
    "Cette fonction renvoie les valeurs des variables **train_size** , **validation_ratio** , **image_axis** , **channels** et **img_shape**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d030df4-1c1c-40c8-9516-3b1b6a5bb967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_params_from_index(dataset_path):\n",
    "    # Récupération des paramètres d'entraînement de l'index\n",
    "    params = pd.read_csv(os.path.join(dataset_path, 'parameters.csv')).dropna()\n",
    "    img_shape = params['img_shape'][0]\n",
    "    channels = params['channels'][0]\n",
    "    image_axis = params['image_axis'][0]\n",
    "    train_size = params['train_size'][0]\n",
    "    validation_ratio = params['validation_ratio'][0]\n",
    "    \n",
    "    img_shape = img_shape[1:-1]\n",
    "    img_shape = tuple(map(int, img_shape.split(', ')))\n",
    "    \n",
    "    channels = channels[1:-1]\n",
    "    channels = list(map(str, channels.split(', ')))\n",
    "    for k in range(len(channels)):\n",
    "        channels[k] = channels[k][1:-1]\n",
    "    \n",
    "    return train_size, validation_ratio, image_axis, channels, img_shape\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2350367f-835e-4cc6-a305-208398f20976",
   "metadata": {},
   "source": [
    "### Construction des subdivisions à partir des fichiers d'index\n",
    "\n",
    "La fonction ci-dessous se charge, à partir des fichiers d'index créés ou fournis, de créer, remplir et sauvegarder les subdivisions des datasets. Ces subdivisions sont stockées au format .npz dans le dossier **./datasets/2d_{N}k/**, où **{N}** est le nombre de milliers d'images (arrondi à l'entier inférieur) incluses dans le dataset d'entraînement.\n",
    "\n",
    "Chaque fichier du dataset d'entraînement est nommé **train_{i}.npz** où **{i}** est le numéro de la subdivision. Les fichiers du dataset de validation sont quant-à-eux nommés **test_{i}.npz**. \n",
    "\n",
    "Cette fonction prend en entrée les variables **dataset_path** , **image_axis** , **channels** et **img_shape**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e58d569-2756-4355-b6e2-c603f6da7564",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_sub_datasets_from_index(dataset_path, image_axis, channels, img_shape):\n",
    "\n",
    "    # Order des canaux dans la base pré-traîtée\n",
    "    channel_order = {\"flair\" : 0, \"t1\" : 1, \"t1ce\" : 2, \"t2\" : 3}\n",
    "    \n",
    "    #Construction des datasets à partir du fichier d'index\n",
    "    index = pd.read_csv(os.path.join(dataset_path, 'index.csv')).dropna()    \n",
    "    sub_names = index.subset_name.unique()\n",
    "    \n",
    "    for subset_name in sub_names:\n",
    "        # Pour chaque subdivision du dataset on sélectionne les images sensées être incluses\n",
    "        subset_index = index.loc[index['subset_name'] == subset_name]\n",
    "        data = np.zeros((len(subset_index.index), img_shape[0], img_shape[1], img_shape[2]))\n",
    "        seg = np.zeros((len(subset_index.index), img_shape[0], img_shape[1]))\n",
    "        subset_files = subset_index.file_name.unique()\n",
    "        \n",
    "        for file in subset_files :\n",
    "            #Pour chaque cas apparaîssant dans cette subdivision, on charge l'image et la segmentation, et on sélectionne le plan de coupe\n",
    "            loaded = np.load(file)\n",
    "            file_data = loaded['data'].swapaxes(0,image_axis)\n",
    "            file_seg = loaded['seg'].swapaxes(0,image_axis)\n",
    "            del loaded\n",
    "            \n",
    "            slices = subset_index.loc[subset_index['file_name'] == file]\n",
    "            for i in range(len(slices.index)): \n",
    "                # Pour chaque coupe\n",
    "                for j in range(len(channels)):\n",
    "                    # Copie des images pour chaque canal selectionné\n",
    "                    data[slices.subset_position.iloc[i],:,:,j] = file_data[slices.slice.iloc[i],:,:,channel_order[channels[j]]]   \n",
    "                # Copie de la carte de segmentation\n",
    "                seg[slices.subset_position.iloc[i],:,:] = file_seg[slices.slice.iloc[i],:,:]   \n",
    "        \n",
    "        # Sauvegarde de la subdivision\n",
    "        np.savez_compressed(subset_name, data=data.astype(\"float32\"), seg=seg.astype(\"byte\"))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186a1501-43dd-4f3c-af84-daa32b834904",
   "metadata": {},
   "source": [
    "### Construction des datasets\n",
    "\n",
    "Cette fonction se charge de construire ou récupérer les datasets pour l'entraînement. Elle applique dans cet ordre les tâches suivantes : \n",
    "\n",
    "-  Récupération de la liste des fichiers pré-traîtés présents dans le dossier **./preprocessed_data/** que l'on joint avec le chemin dudit dossier, et on stocke le tout dans la liste **path_to_data**. \n",
    "-  Chargement du premier fichier de cette liste pour mesurer la taille des images que l'on aura à traîter, stockée dans le tuple **img_shape**. Les deux premiers champs de ce tuple contiennent les dimensions par canal de chaque image, le troisième champ contient le nombre de canaux utilisés pour l'apprentissage, et le dernier champ indique le nombre de coupes qu'il est possible de faire dans chaque fichier. \n",
    "-  Vérification de la taille du dataset. Si la taille demandée est supérieure au nombre d'images présentes dans la base, on recalcule la valeur de la variable **train_size** pour que toutes les images soient incluses dans le dataset en conservant la même valeur de **validation_ratio**.\n",
    "-  Si nécessaire, construction des fichiers d'index en appelant la fonction dédiée.\n",
    "-  Récupération des paramètres dans le fichier de paramètres, à l'aide de la fonction adéquate. Si ces paramètres sont différents de ceux entrés précédemments car extraits d'un fichier d'index pré-existant, ils les écrasent.\n",
    "-  Si nécessaire, Création des subdivisions des datasets en appelant la fonction dédiée.\n",
    "-  Récupération dans les fichiers d'index les noms et chemins des fichiers de subdivision, que l'on stocke sous forme de liste dans **train_dataset** pour les données d'entraînement et dans **test_dataset** pour les données de validation.\n",
    "\n",
    "Cette fonction prend en entrée les paramètres de création des datasets, et renvoie ces mêmes paramètres, mis à jour s'ils sont issus des fichiers d'index, ainsi que les listes **train_dataset** et **test_dataset** et le tuple de mesure des dimensions des images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1550c442-e1ce-4266-80d6-746524b0621d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_datasets(train_size, validation_ratio, image_axis, channels, reuse=False, rebuild=True):\n",
    "    \n",
    "    # Récupération des chemins des fichiers pré-traîtés\n",
    "    list_of_files = os.listdir('./preprocessed_data/')\n",
    "    path_to_data = []\n",
    "    for file in list_of_files:\n",
    "        path_to_data.append(os.path.join('preprocessed_data', file))\n",
    "\n",
    "    # Taille des images d'entrée   \n",
    "    loaded = np.load(path_to_data[0])\n",
    "    img = loaded['data'].swapaxes(0,image_axis)\n",
    "    img_shape = (img.shape[1], img.shape[2], len(channels), img.shape[0])\n",
    "    del img, loaded\n",
    "    \n",
    "    # Vérification de la taille du dataset\n",
    "    if train_size + int(np.floor(train_size * validation_ratio)) > (335*img_shape[3]) :\n",
    "        train_size = 335*img_shape[3] - int(np.floor((335*img_shape[3]*validation_ratio)/(1+validation_ratio)))\n",
    "    \n",
    "    # Construction des fichiers d'index\n",
    "    dataset_path = os.path.join('datasets', '2d_{0:d}k'.format(train_size//1000))\n",
    "    if not(reuse & os.path.exists(os.path.join(dataset_path, 'index.csv')) & os.path.exists(os.path.join(dataset_path, 'index.csv'))) :\n",
    "        build_index(path_to_data, dataset_path, train_size, validation_ratio, image_axis, channels, img_shape)\n",
    "        rebuild = True\n",
    "        \n",
    "    # Lecture des paramètres inclus dans le fichier de paramètres\n",
    "    train_size, validation_ratio, image_axis, channels, img_shape = read_params_from_index(dataset_path)\n",
    "    \n",
    "    # Construction des subdivisions\n",
    "    if rebuild :\n",
    "        build_sub_datasets_from_index(dataset_path, image_axis, channels, img_shape)\n",
    "    \n",
    "    # Création des listes des fichiers de subdivisions des ensembles d'entraînement et de validation.\n",
    "    index = pd.read_csv(os.path.join(dataset_path, 'index.csv')).dropna()\n",
    "    sub_names = index.subset_name.unique()\n",
    "    train_dataset = []\n",
    "    test_dataset = []\n",
    "    for sub_name in sub_names :\n",
    "        if index[index.subset_name==sub_name].train_or_test.iloc[0] == 'train':\n",
    "            train_dataset.append(sub_name + '.npz')\n",
    "        else:\n",
    "            test_dataset.append(sub_name + '.npz')\n",
    "            \n",
    "    return train_dataset, test_dataset, train_size, validation_ratio, image_axis, channels, img_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06c3d9b-9aec-48ba-8cbb-b52c3f54ef9f",
   "metadata": {},
   "source": [
    "Il suffit ensuite d'une ligne pour gérer entièrement la création des datasets :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce990af-8479-4529-80d1-0c7f3b5ebdee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset, test_dataset, train_size, validation_ratio, image_axis, channels, img_shape = build_datasets(train_size, validation_ratio, image_axis, channels, reuse=reuse_index, rebuild=rebuild_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02091e14-3942-42e0-8db9-8bfef76dbb5d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Création du modèle\n",
    "\n",
    "Le réseau de neurones utilisé pour réaliser cette segmentation est basé sur l'architecture [U-Net](https://fr.wikipedia.org/wiki/U-Net). Cette architecture est particulièrement adaptée à la segmentation d'images. Ce modèle est composé de blocs de trois natures différentes :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84718daa-80d1-4fdd-bb90-7f7ab8fdb61d",
   "metadata": {},
   "source": [
    "### Bloc d'encodage\n",
    "\n",
    "Ce bloc a pour tâche de compresser les données, en réduisant leur dimension spatiale mais en augmentant leur dimension sémantique. Il est composé de :\n",
    "-  Une couche de convolution 2D comprenant un nombre de filtres grandissant avec la profondeur dans le réseau\n",
    "-  Une couche de normalisation qui peut être shuntée\n",
    "-  Une couche d'activation *Leaky ReLU*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed18587e-39fd-44ea-a551-da712af0c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_block(layer_in, n_filters, stride, apply_batchnorm=True):\n",
    "    init = tf.random_normal_initializer(0., 0.02, 0)\n",
    "    g = Conv2D(n_filters, (stride+2,stride+2), strides=(stride,stride), padding='same', kernel_initializer=init)(layer_in)\n",
    "    if apply_batchnorm:\n",
    "        g = BatchNormalization()(g, training=True)\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1af5498-e2b4-4619-8fd5-0f2871a9e424",
   "metadata": {},
   "source": [
    "### Goulot d'étranglement\n",
    "\n",
    "Ce bloc traîte les données issues de la cascade d'encodage, sans en modifier la dimmensionnalité. Il est composé de trois couches de convolution 2D suivies chacune d'une couche d'activation ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c91f2d-c0c7-4952-8996-235d6d882077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bottleneck(layer_in, n_filters):\n",
    "    init = tf.random_normal_initializer(0., 0.02, 0)\n",
    "    # bottleneck, no batch norm and relu\n",
    "    b1 = Conv2D(n_filters, (3,3), strides=(1,1), padding='same', kernel_initializer=init)(layer_in)\n",
    "    b1 = Activation('relu')(b1)\n",
    "    b2 = Conv2D(n_filters, (3,3), strides=(1,1), padding='same', kernel_initializer=init)(b1)\n",
    "    b2 = Activation('relu')(b2)\n",
    "    b3 = Conv2D(n_filters, (3,3), strides=(1,1), padding='same', kernel_initializer=init)(b2)\n",
    "    b3 = Activation('relu')(b3)\n",
    "    return b3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac617a97-5cae-4171-89bc-d585db746398",
   "metadata": {},
   "source": [
    "### Bloc de décodage\n",
    "\n",
    "Ce bloc a pour tâche de décompresser les données issues de la couche précédente et de les mettre en relation avec les données sorties du bloc d'encodage de même dimmensionnalité, avant le goulot d'étranglement. Il est composé de :\n",
    "-  Une couche de déconvolution 2D dont le nombre de filtres diminue avec la profondeur du réseau\n",
    "-  Une couche de normalisation\n",
    "-  Une couche de *dropout*\n",
    "-  Une couche de concaténation des données d'agrégation avec les données issues du bloc d'encodage\n",
    "-  Une couche d'activation *ReLU*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ad448e-fc33-4efe-a4fd-aa66e104214d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoding_block(layer_in, skip_in, n_filters, stride, dropout=True):\n",
    "    init = tf.random_normal_initializer(0., 0.02, 0)\n",
    "    g = Conv2DTranspose(n_filters, (stride+2,stride+2), strides=(stride,stride), padding='same', kernel_initializer=init)(layer_in)\n",
    "    g = BatchNormalization()(g, training=True)\n",
    "    if dropout:\n",
    "        g = Dropout(0.2)(g, training=True)\n",
    "    g = Concatenate()([g, skip_in])\n",
    "    g = Activation('relu')(g)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826a3726-37ff-4d99-9eb2-998dd6a7cd40",
   "metadata": {},
   "source": [
    "### Réseau complet\n",
    "\n",
    "Le réseau s'architecture de la façon suivante : \n",
    "-  Une étape d'encodage constituée de 5 blocs d'encodage successifs, divisant chacun la taille des images par 2 ou 3 et augmentant la profondeur du tenseur de données à chaque couche, permettant d'atteindre une profondeur de 1024 canaux\n",
    "-  Un goulot d'étranglement\n",
    "-  Une étape de décodage constituée de 5 blocs de décodage réduisant la profondeur du tenseur de données jusqu'à 64 canaux\n",
    "-  Une dernière couche de déconvolution suivie du'une couche d'activation *softmax* permettant d'effectuer la classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcf6656-3bbc-47cc-b5f0-d183e04ad3cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_unet(image_shape):\n",
    "    \n",
    "    init = tf.random_normal_initializer(0., 0.02, 0)\n",
    "    inputs = Input(shape=image_shape[:3])\n",
    "    \n",
    "    # Encodage\n",
    "    e1 = encoding_block(inputs, 64, 2, apply_batchnorm=False) # Taille de sortie : (120x120x64) ou (120x72x64)\n",
    "    e2 = encoding_block(e1, 128, 2)                            # Taille de sortie : (60x60x128) ou (60x36x128)\n",
    "    e3 = encoding_block(e2, 256, 2)                           # Taille de sortie : (30x30x256) ou (30x18x256)\n",
    "    e4 = encoding_block(e3, 512, 2)                           # Taille de sortie : (15x15x512) ou (15x9x512)\n",
    "    e5 = encoding_block(e4, 512, 3)                           # Taille de sortie : (5x5x1024) ou (5x3x1024)\n",
    "    \n",
    "    # Goulot d'étranglement\n",
    "    b = bottleneck(e5, 512)\n",
    "    \n",
    "    # Décodage\n",
    "    d1 = decoding_block(b, e5, 512, 1)\n",
    "    d2 = decoding_block(d1, e4, 512, 3)\n",
    "    d3 = decoding_block(d2, e3, 512, 2, dropout=False)\n",
    "    d4 = decoding_block(d3, e2, 256, 2, dropout=False)\n",
    "    d5 = decoding_block(d4, e1, 128, 2, dropout=False)\n",
    "    \n",
    "    # Sortie\n",
    "    g = Conv2DTranspose(5, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d5)\n",
    "    output = Activation('softmax')(g)\n",
    "    \n",
    "    # Construction du modèle\n",
    "    model = Model(inputs, output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c9b637-303d-4a1d-ba67-81fc262a3d0c",
   "metadata": {},
   "source": [
    "### Construction du modèle\n",
    "\n",
    "Le morceau de code suivant permet le chargement ou la construction du modèle. \n",
    "\n",
    "Si la variable booléenne **load_model** est à ***True***, le programme cherche s'il existe un modèle pré-existant et si oui il le charge. Ce modèle doit être situé dans le dossier **./models/**, et nommé **Model_2d_{N}k.hdf5**, où **{N}** est le nombre de milliers d'images (arrondi à l'entier inférieur) incluses dans le dataset d'entraînement.\n",
    "\n",
    "Si ce modèle n'existe pas, ou si **load_model** est à ***False***, le programme le crée et le compile en utilisant l'optimiseur *Adam* avec un taux d'apprentissage à 2e-4. Si un modèle avec ce nom existait précédemment, il est écrasé.\n",
    "\n",
    "La fonction de coût (*Loss*) est une entropie binaire croisée, idéale pour les tâches de classification.\n",
    "\n",
    "Enfin, on affiche le résumé de l'archtecture du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3810344a-44dc-4099-bfb7-be5dea7fe2b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "load_model = False\n",
    "if load_model & os.path.exists(os.path.join('models', 'Model_2d_{0:d}k.hdf5'.format(train_size//1000))):\n",
    "    unet_model = tf.keras.models.load_model(os.path.join('models', 'Model_2d_{0:d}k.hdf5'.format(train_size//1000)))\n",
    "else :\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "    unet_model = build_unet(img_shape)\n",
    "    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    unet_model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), optimizer=opt, loss_weights=[0.5])\n",
    "    tf.keras.models.save_model(unet_model, os.path.join('models', 'Model_2d_{0:d}k.hdf5'.format(train_size//1000)))\n",
    "\n",
    "unet_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ba6722-0f9e-4387-8aef-0221f7c4eb7e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Mesure des performances du modèle\n",
    "\n",
    "Cette section détaille la façon dont le performances du réseau sont mesurées et visualisées"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4cb239-b259-4138-9e59-6e31c3b7d450",
   "metadata": {},
   "source": [
    "### Visualisation des résultats\n",
    "\n",
    "Cette fonction se charge d'afficher les résultats du réseau, en affichant côte-à-côte les données d'entrée, la carte de segmentation issue du dataset et la carte de segmentation générée par le réseau de neurones. \n",
    "\n",
    "Chaque ligne de la sortie correspond à une image d'entrée. Les données d'entrée sont affichées dans l'ordre de la liste **channels**, suivie de la carte de segmentation originale, et enfin la carte de prédiction. Le nombre de ligne à afficher est donné par la taille du batch.\n",
    "\n",
    "Cette fonction prend en entrée les cartes de données **data**, la carte de segmentation prédite **pred**, la carte de segmentation originale **seg** et le nombre d'images dans le batch **n_sample**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c25809d-943b-4367-921f-32f38676873d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize(data, pred, seg, n_sample):\n",
    "\n",
    "    n_img_per_case = 2 + data.shape[3]\n",
    "    plt.figure(figsize=(5*n_img_per_case, 5*n_sample))\n",
    "    \n",
    "    for i in range(n_sample):\n",
    "        \n",
    "        for j in range(data.shape[3]):\n",
    "            plt.subplot(n_sample, n_img_per_case, n_img_per_case * i + j + 1)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.grid(False)\n",
    "            plt.imshow(data[i,:,:,j], vmin=-1, vmax=1)\n",
    "        \n",
    "        plt.subplot(n_sample, n_img_per_case, n_img_per_case * (i + 1) - 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(seg[i,:,:], vmin=0, vmax=4)\n",
    "            \n",
    "        plt.subplot(n_sample, n_img_per_case, n_img_per_case * (i + 1))\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(pred[i,:,:], vmin=0, vmax=4)\n",
    "\n",
    "    plt.show()\n",
    "    return    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec8b0ff-bc95-4e2d-b006-b2583437a97e",
   "metadata": {},
   "source": [
    "### Mesure des performances\n",
    "\n",
    "Cette fonction calcule et affiche les performances du modèle sur un dataset. Pour cela, on calcule la précision, la sensibilité et le score F1 pour chaque image du dataset et pour chaque classe.\n",
    "\n",
    "Ces grandeurs sont définies de la façons suivante (pour l'image $i$ et la classe $k$): \n",
    "-  Sensibilité : $S_{ik} = \\frac{TP}{TP + FP}$\n",
    "-  Précision : $P_{ik} = \\frac{TP}{TP + FP}$\n",
    "-  Score F1 : $F1_{ik} = \\frac{2.S.P}{S+P}$\n",
    "\n",
    "avec \n",
    "-  $TP$ le nombre de vrais positifs (nombre de pixels de l'image $i$ correctement classifiés dans la classe $k$)\n",
    "-  $FP$ le nombre de faux positifs (nombre de pixels de l'image $i$ classifiés dans la classe $k$ mais appartenant à une autre classe)\n",
    "-  $FN$ le nombre de faux négatifs (nombre de pixels de l'image $i$ appartenant à la classe $k$ mais classifiés dans une autre classe)\n",
    "\n",
    "On agrège ensuite les résultats en effectuant une moyenne pondérée par classe sur les images. En notant $N_{ik}$ le nombre de pixels de l'image $i$ appartenant à la classe $k$ et $X_k$ le score pour la classe $k$ pour lequel on agrège les résultats des $X_{ik}$, on a :\n",
    "\\begin{equation} \n",
    "\\mathbb{E}[X_k] = \\dfrac{\\sum_i N_{ik}.X_{ik}}{\\sum_i N_{ik}}\n",
    "\\end{equation}\n",
    "Et :\n",
    "\\begin{equation} \n",
    "\\sigma[X_k] = \\sqrt{\\dfrac{\\sum_i N_{ik}^2.X_{ik}^2}{\\sum_i N_{ik}^2} - \\mathbb{E}[X_k]^2}\n",
    "\\end{equation}\n",
    "\n",
    "On affiche les résultats sous la forme $\\mathbb{E}[X_k] \\pm \\sigma[X_k]$\n",
    "\n",
    "On calcule ensuite les scores globaux en agrégeant sur les classes. En notant $X$ le score global d'une image, on a :\n",
    "\\begin{equation} \n",
    "\\mathbb{E}[X] = \\frac{\\sum_k \\sum_i N_{ik}.X_{ik}}{\\sum_k \\sum_i N_{ik}}\n",
    "\\end{equation}\n",
    "Et : \n",
    "\\begin{equation} \n",
    "\\sigma[X] = \\sqrt{\\frac{\\sum_k \\sum_i N_{ik}^2.X_{ik}^2}{\\sum_k \\sum_i N_{ik}^2} - \\mathbb{E}[X]^2}\n",
    "\\end{equation}\n",
    "\n",
    "En plus de cela, on calcule également les précision, sensibilité et score F1 binaires, mesurent si chaque pixel a correctement été catégorisé comme tumoral, sans se soucier de quel type de tissu tumoral il s'agit.\n",
    "\n",
    "Pour finir, si la variable booléenne d'entrée **show** est à ***True***, on appelle la fonction de visualisation pour afficher le dernier batch prédit par le réseau.\n",
    "\n",
    "Cette fonction prend en entrée le modèle **unet_model**, la liste **dataset** des noms des fichiers de subdivision appartenant au dataset à mesurer, la taille des batchs **batch_size** à faire passer dans le réseau (optionnel, 10 par défaut), et la variable **show**.\n",
    "\n",
    "Elle renvoie les moyennes et écarts-types des scores par classe, globaux et binaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db441685-67b7-4688-aba8-673b2f097a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_performance(unet_model, dataset, batch_size = 10, show=False):\n",
    "    \n",
    "    scores_weighted_sum = np.zeros((4,5), dtype='float64')\n",
    "    scores_weighted_squares = np.zeros((4,5), dtype='float64')\n",
    "    class_scores = np.zeros((4,2,5), dtype='float64')\n",
    "    global_scores = np.zeros((4,2), dtype='float64')\n",
    "    binary_scores = np.zeros((4,2), dtype='float64')\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        loaded = np.load(dataset[i])\n",
    "        data = loaded['data']\n",
    "        seg = loaded['seg']       \n",
    "        del loaded\n",
    "        n_batch = int(np.floor(data.shape[0]/batch_size))\n",
    "        \n",
    "        for j in range(n_batch):\n",
    "            batch_data = data[j*batch_size:(j+1)*batch_size,:,:,:]\n",
    "            batch_seg = seg[j*batch_size:(j+1)*batch_size,:,:]\n",
    "            batch_pred = np.argmax(unet_model.predict(batch_data, verbose=0), axis=3)\n",
    "            for k in range(batch_size):\n",
    "                precision, recall, F1, support = precision_recall_fscore_support(batch_seg[k,:,:].flatten(), batch_pred[k,:,:].flatten(), \n",
    "                                                                                 labels=np.asarray([0, 1, 2, 3, 4]), zero_division=0)\n",
    "\n",
    "                results = (np.concatenate((precision.reshape((1,5)), recall.reshape((1,5)), F1.reshape((1,5)), np.ones((1,5))), axis=0) * np.dot(np.ones((4,1)), support.reshape((1,5)))).reshape((4,1,5))\n",
    "                class_scores += np.concatenate((results, results**2), axis=1)\n",
    "                \n",
    "                precision, recall, F1, support = precision_recall_fscore_support((batch_seg[k,:,:].flatten() >= 2).astype(int), (batch_pred[k,:,:].flatten() >= 2).astype(int), labels=[1], zero_division=0)\n",
    "                results = np.asarray([precision, recall, F1, [1]]) * support\n",
    "                binary_scores += np.concatenate((results, results ** 2), axis=1)\n",
    "                \n",
    "    global_scores = class_scores.sum(axis=2)\n",
    "    \n",
    "    for k in range(5):\n",
    "        class_scores[:3,:,k] /= np.dot(np.ones((3,1)), class_scores[3,:,k].reshape((1,2)))\n",
    "        class_scores[:3,1,k] = np.sqrt(class_scores[:3,1,k] - class_scores[:3,0,k]**2)\n",
    "        print(\"Performances pour la classe {0:d} ({1:d} pixels) : Précision {2:.3f}% \\u00B1 {3:.3f}% - Sensibilité {4:.3f}% \\u00B1 {5:.3f}% - F1 {6:.3f}% \\u00B1 {7:.3f}%\"\n",
    "              .format(k, int(class_scores[3,0,k]), class_scores[0,0,k]*100, class_scores[0,1,k]*100, class_scores[1,0,k]*100, class_scores[1,1,k]*100, class_scores[2,0,k]*100, class_scores[2,1,k]*100))    \n",
    "    \n",
    "    global_scores[:3,:] /= np.dot(np.ones((3,1)), global_scores[3,:].reshape((1,2)))\n",
    "    global_scores[:3,1] = np.sqrt(global_scores[:3,1] - global_scores[:3,0]**2)\n",
    "    print(\"Performances globales ({0:d} pixels) : Précision {1:.3f}% \\u00B1 {2:.3f}% - Sensibilité {3:.3f}% \\u00B1 {4:.3f}% - F1 {5:.3f}% \\u00B1 {6:.3f}%\"\n",
    "          .format(int(global_scores[3,0]), global_scores[0,0]*100, global_scores[0,1]*100, global_scores[1,0]*100, global_scores[1,1]*100, global_scores[2,0]*100, global_scores[2,1]*100))\n",
    "    \n",
    "    binary_scores[:3,:] /= np.dot(np.ones((3,1)), binary_scores[3,:].reshape((1,2)))\n",
    "    binary_scores[:3,1] = np.sqrt(binary_scores[:3,1] - binary_scores[:3,0]**2)\n",
    "    \n",
    "    print(\"Performances binaires ({0:d} pixels) : Précision {1:.3f}% \\u00B1 {2:.3f}% - Sensibilité {3:.3f}% \\u00B1 {4:.3f}% - F1 {5:.3f}% \\u00B1 {6:.3f}%\"\n",
    "          .format(int(binary_scores[3,0]), binary_scores[0,0]*100, binary_scores[0,1]*100, binary_scores[1,0]*100, binary_scores[1,1]*100, binary_scores[2,0]*100, binary_scores[2,1]*100))\n",
    "    \n",
    "    if show :\n",
    "        visualize(batch_data, batch_pred, batch_seg, batch_size)\n",
    "    \n",
    "    return class_scores, global_scores, binary_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0186e3d9-8f4e-4794-b4b8-c7c69037f085",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Entraînement du modèle\n",
    "\n",
    "Ici on détaille comment se déroule l'entraînement du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94590341-25b9-48ef-9495-ec7f1f71a6ac",
   "metadata": {},
   "source": [
    "### Fonction d'entraînement\n",
    "\n",
    "Cette fonction gère l'organisation de l'entraînement.\n",
    "\n",
    "A chaque époque, on charge successivement toutes les subdivisions du dataset d'entraînement, que l'on mélange puis divise en batchs. Ce mélange permet de s'assurer de ne pas passer systématiquement les mêmes données dans le même ordre, ce qui dégraderait la qualité de l'entraînement. Le réseau est ensuite entraîné batch par batch.\n",
    "\n",
    "Après chaque époque, le modèle est sauvegardé, et on affiche la valeur moyenne de la fonction de coût sur l'ensemble des batchs, ainsi que des informations concernant l'avancement, le temps écoulé depuis le début de l'entraînement, la durée totale d'entraînement estimée et le temps restant.\n",
    "\n",
    "Enfin, toutes les 10 époques, on mesure les performances du réseau sur le dataset de validation, et on en profite pour visualiser un batch de ce dataset.\n",
    "\n",
    "Cette fonction prend en entrée le modèle **unet_model**, les listes **train_dataset** et **test_dataset** des noms des fichiers de subdivision respectivement du dataset d'entraînement et du dataset de validation, la taille totale du dataset d'entraînement **train_size**, le nombre d'époques d'entraînement **n_epochs** (optionnel, 100 par défaut) et la taille des batchs **batch_size** (optionnel, 10 par défaut)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e8bb12-cee5-426f-b491-b3292c2bb030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(unet_model, train_dataset, test_dataset, train_size, n_epochs=100, batch_size=10):\n",
    "\n",
    "    start_time = time.time()\n",
    "    for epoch in range(n_epochs):\n",
    "        batch_losses = np.zeros(int(np.floor(train_size/batch_size)))\n",
    "        k_batch = 0\n",
    "        for k in range(len(train_dataset)):\n",
    "            loaded = np.load(train_dataset[k])\n",
    "            data = loaded['data']\n",
    "            seg = loaded['seg']\n",
    "            del loaded\n",
    "        \n",
    "            # Mélange du dataset\n",
    "            rp = np.random.permutation(data.shape[0])\n",
    "            n_batch = int(np.floor(data.shape[0]/batch_size))            \n",
    "            \n",
    "            for batch in range(n_batch):\n",
    "                batch_data = data[rp[batch*batch_size : (batch+1)*batch_size],:,:,:]\n",
    "                batch_seg = to_categorical(seg[rp[batch*batch_size : (batch+1)*batch_size],:,:], num_classes=5)\n",
    "                batch_losses[k_batch] = unet_model.train_on_batch(batch_data, batch_seg)\n",
    "                k_batch += 1\n",
    "        \n",
    "        tf.keras.models.save_model(unet_model, os.path.join('models', 'Model_2d_{0:d}k.hdf5'.format(train_size//1000)))\n",
    "        \n",
    "        if (epoch+1)%10 == 0 :\n",
    "            print(\"Evaluation des performances\")\n",
    "            class_scores, global_scores, binary_scores = measure_performance(unet_model, test_dataset, batch_size = 10, show=True)\n",
    "            \n",
    "        stop_time = time.time()\n",
    "        avancement = (epoch+1)/(n_epochs)\n",
    "        duree = stop_time - start_time\n",
    "        duree_totale = duree / avancement\n",
    "        ETA = duree_totale - duree\n",
    "        print(\"Avancement : {0:.2f}%, Temps écoulé : {1:d}h {2:02d}m {3:02d}s, Temps restant estimé: {4:d}h {5:02d}m {6:02d}s, Loss = {7:.6f}\"\n",
    "              .format(round(100*avancement,2), int(duree)//3600, (int(duree)//60)%60, int(duree)%60, int(ETA)//3600, (int(ETA)//60)%60, int(ETA)%60, np.mean(batch_losses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cb7d65-9480-40ca-96fb-42357e0074e5",
   "metadata": {},
   "source": [
    "### Exécution de l'entraînement\n",
    "\n",
    "Ici, on exécute la fonction d'entraînement. On peut auparavant choisir le nombre d'époques d'entraînement **n_epochs** et la taille des batchs **batch_size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9547ef5-ef08-4922-a76c-efb91dee1068",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "n_epochs = 100\n",
    "\n",
    "train(unet_model, train_dataset, test_dataset, train_size, n_epochs=n_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2dc8d3-25f0-4b77-a5e7-c39b0948a105",
   "metadata": {},
   "source": [
    "### Mesures des performances\n",
    "\n",
    "Ici, on évalue les performances du modèle sur l'ensemble d'entraînement et sur l'ensemble de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d82564-2a90-4156-911b-4b2dbe19f8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mesures des performances sur le dataset d'entraînement : \")\n",
    "class_scores, global_scores, binary_scores = measure_performance(unet_model, train_dataset, batch_size = 10, show=False)\n",
    "print(\"\\n\\nMesures des performances sur le dataset de validation : \")\n",
    "class_scores, global_scores, binary_scores = measure_performance(unet_model, test_dataset, batch_size = 10, show=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
